{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "# For interactive debugging\n",
    "from IPython.core.debugger import set_trace as bp\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "import data_handler\n",
    "from data_handler import *\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options/ Hyperparameters required to train and test the model\n",
    "opts = EasyDict()\n",
    "\n",
    "opts.n_epochs = 100\n",
    "opts.batch_size = 16\n",
    "opts.optimizer = \"RMSprop\" #\"Adam\"\n",
    "opts.learning_rate = 0.005\n",
    "opts.lr_decay = 0.99\n",
    "opts.hidden_layer_size = 100\n",
    "opts.model_name = \"LSTM\"\n",
    "opts.checkpoints_dir = \"./checkpoints/{}_{}_lr_{}_epochs_{}\".format(opts.model_name,opts.optimizer,opts.learning_rate,opts.n_epochs)\n",
    "opts.temp = 0.4\n",
    "opts.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TEST_SENTENCE = 'i love deep learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_dir_if_not_exists(opts.checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pairs, vocab_size, idx_dict = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_to_index\n",
      "{'-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'SOS': 27, 'EOS': 28}\n",
      "index_to_char\n",
      "{0: '-', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'SOS', 28: 'EOS'}\n",
      "start_token\n",
      "27\n",
      "end_token\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for key in (idx_dict.keys()):\n",
    "    print(key)\n",
    "    print(idx_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the line pairs into 8:2, train and val split\n",
    "num_lines = len(line_pairs)\n",
    "num_train = int(0.8 * num_lines)\n",
    "train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = create_dict(train_pairs)\n",
    "val_dict = create_dict(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Structure of train_dict and val_dict variables\n",
    "\n",
    "#for key in train_dict.keys():\n",
    "#    print(\"Pairs of length {}: {}\".format(key,len(train_dict[key])))\n",
    "# train_dict[(1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your own LSTM cell. A sample class definition is given to you.\n",
    "\n",
    "class MyLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_i = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_c = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "                        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        \"\"\"Forward pass of the LSTM computation for one time step.\n",
    "\n",
    "        Arguments\n",
    "            x: batch_size x input_size\n",
    "            h_prev: batch_size x hidden_size\n",
    "            c_prev: batch_size x hidden_size\n",
    "        Returns:\n",
    "            h_new: batch_size x hidden_size\n",
    "            c_new: batch_size x hidden_size\n",
    "        \"\"\"\n",
    "        x_combined = torch.cat((x, h_prev), 1)\n",
    "\n",
    "        f = torch.sigmoid(self.W_f(x_combined))\n",
    "        i = torch.sigmoid(self.W_i(x_combined))\n",
    "        o = torch.sigmoid(self.W_o(x_combined))\n",
    "        c_dash = torch.tanh(self.W_c(x_combined))\n",
    "        \n",
    "        c_new = f*c_prev + i*c_dash\n",
    "        h_new = o*torch.tanh(c_new)\n",
    "        \n",
    "        return h_new, c_new\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.LSTMCell = MyLSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        cell = self.init_hidden(batch_size)\n",
    "        annotations = torch.empty((batch_size, seq_len, self.hidden_size), dtype=hidden.dtype)\n",
    "        \n",
    "        # The encoded embeddings should be of size batch_size x seq_len x hidden_size        \n",
    "        encoded_embeddings = self.embeddings(inputs)\n",
    "        \n",
    "        # Loop over the time-steps do forward pass through LSTM cell at each ti\n",
    "        for i in range(seq_len):\n",
    "            hidden,cell = self.LSTMCell.forward(encoded_embeddings[:,i,:], hidden, cell)\n",
    "            annotations[:,i,:] = hidden\n",
    "            \n",
    "        return annotations, cell, hidden\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return torch.zeros(bs, self.hidden_size)\n",
    "\n",
    "\n",
    "# Implement your Decoder RNN using instances of LSTM Cell you just created.\n",
    "# You would need a character embedding layer for this. \n",
    "# In addition you would also require an activation function applied to the output of the LSTM Cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.LSTMCell = MyLSTMCell(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        \"\"\"Forward pass of the decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            x: Input token indexes across a batch for a single time step. (batch_size x 1)\n",
    "            h_prev: The hidden states from the previous step, across a batch. (batch_size x hidden_size)\n",
    "            c_prev: The cell states from the previous step, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch. (batch_size x vocab_size)\n",
    "            h_new: The new hidden states, across a batch. (batch_size x hidden_size)\n",
    "            c_new: The new cell states, across a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "    \n",
    "        encoded_embeddings = self.embeddings(x).squeeze(1)\n",
    "        h_new, c_new = self.LSTMCell.forward(encoded_embeddings, h_prev, c_prev)\n",
    "        output = self.output(h_new)\n",
    "        \n",
    "        return output, h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Create Encoder, Decoder Objects \n",
    "\n",
    "encoder = Encoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size).to(opts.device)\n",
    "decoder = Decoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size).to(opts.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        opts: The input arguments for hyper-parameters and others.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    parameters = list(encoder.parameters())+list(decoder.parameters())\n",
    "    \n",
    "    if opts.optimizer == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(parameters ,lr=opts.learning_rate)\n",
    "        # print(\"RMSProp\")\n",
    "    elif opts.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(parameters ,lr=opts.learning_rate)\n",
    "        # print(\"Adam\")\n",
    "    else:\n",
    "        optimizer = optim.SGD(parameters, lr=opts.learning_rate, momentum=0.9)\n",
    "        # print(\"SGD\")\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoints_dir, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(opts.n_epochs):\n",
    "        \n",
    "        # decay the learning rate of the optimizer\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "\n",
    "        epoch_losses = []\n",
    "\n",
    "        for key in train_dict:\n",
    "            input_strings, target_strings = zip(*train_dict[key])\n",
    "\n",
    "            input_tensors, output_tensors = [],[]\n",
    "            for s in input_strings:\n",
    "                input_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "            for s in target_strings:\n",
    "                output_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "                \n",
    "            num_tensors = len(input_tensors)\n",
    "            num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "            \n",
    "            for i in range(num_batches):\n",
    "                start = i * opts.batch_size\n",
    "                end = start + opts.batch_size\n",
    "                \n",
    "                # Define inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "                inputs = torch.stack(input_tensors[start:end]).to(opts.device)\n",
    "                targets = torch.stack(output_tensors[start:end]).to(opts.device)\n",
    "                \n",
    "                #print (\"targets\", targets.size(), \"\\n\" ,targets)\n",
    "                # The batch size may be different in each epoch\n",
    "                BS = inputs.size(0)\n",
    "\n",
    "                encoder_annotations, encoder_cell, encoder_hidden = encoder.forward(inputs)\n",
    "\n",
    "                # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "                decoder_hidden = encoder_hidden\n",
    "                decoder_cell = encoder_cell\n",
    "\n",
    "                # Define the first decoder input. This would essentially be the start_token\n",
    "                decoder_input = start_token * torch.ones(BS,1).long()\n",
    "\n",
    "                loss = 0.0\n",
    "\n",
    "                seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "                \n",
    "                for si in range(seq_len):\n",
    "                    decoder_output, decoder_hidden, decoder_cell = decoder.forward(decoder_input, decoder_hidden, decoder_cell)\n",
    "\n",
    "                    current_target = targets[:,si]\n",
    "                    # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                    loss += criterion(decoder_output, current_target)\n",
    "                    \n",
    "                    decoder_input = targets[:,si].unsqueeze(1)\n",
    "\n",
    "                loss /= float(seq_len)\n",
    "                epoch_losses.append(loss.item())\n",
    "                \n",
    "                # Compute gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the parameters of the encoder and decoder\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Reset gradient\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        train_loss = np.mean(epoch_losses)\n",
    "        val_loss = evaluate(val_dict, encoder, decoder, idx_dict, criterion, opts)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            utils.store_checkpoints(encoder, decoder, idx_dict, opts)\n",
    "\n",
    "        gen_string = find_pig_latin(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        #print(gen_string)\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        utils.store_loss_plots(train_losses, val_losses, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_dict, encoder, decoder, idx_dict, criterion, opts):\n",
    "    \"\"\"Evaluates the model on a held-out validation or test set. \n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for key in data_dict:\n",
    "\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "\n",
    "        input_tensors, output_tensors = [],[]\n",
    "        for s in input_strings:\n",
    "            input_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "        for s in target_strings:\n",
    "            output_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            # Define inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "            inputs = torch.stack(input_tensors[start:end])\n",
    "            targets = torch.stack(output_tensors[start:end])\n",
    "\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_cell ,encoder_hidden = encoder.forward(inputs)\n",
    "            \n",
    "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "            # Define the first decoder input. This would essentially be the start_token\n",
    "            decoder_input = start_token * torch.ones(BS,1).long()\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "            #print(\"seq len\", seq_len)\n",
    "            \n",
    "            for i in range(seq_len):\n",
    "                decoder_output, decoder_hidden, decoder_cell = decoder.forward(decoder_input, decoder_hidden, decoder_cell)\n",
    "\n",
    "                current_target = targets[:,i]\n",
    "\n",
    "                # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                loss += criterion(decoder_output, current_target)\n",
    "                # Find out the most probable character (ni) from the softmax distribution produced\n",
    "                ni = F.softmax(decoder_output,dim=1).max(1)\n",
    "                \n",
    "                # Update decoder_input at the next time step to be this time-step's target \n",
    "                decoder_input = targets[:,i].unsqueeze(1)\n",
    "\n",
    "            loss /= float(seq_len)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pig_latin(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    \n",
    "    #print(\"end token\", end_token)\n",
    "    \n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "    \n",
    "    # convert given string to an array of indexes\n",
    "    indexes = torch.LongTensor(string_to_index_list(input_string, char_to_index, end_token)).unsqueeze(0)\n",
    "\n",
    "    encoder_annotations, encoder_last_cell, encoder_last_hidden = encoder.forward(indexes)\n",
    "\n",
    "    # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "    decoder_hidden = encoder_last_hidden\n",
    "    #decoder_cell = torch.zeros(1, encoder.hidden_size)\n",
    "    decoder_cell = encoder_last_cell\n",
    "\n",
    "    # Define the first decoder input. This would essentially be the start_token\n",
    "    decoder_input = start_token * torch.ones(1,1).long()\n",
    "    \n",
    "    for i in range(max_generated_chars):\n",
    "        decoder_output, decoder_hidden, decoder_cell = decoder.forward(decoder_input, decoder_hidden, decoder_cell)\n",
    "        \n",
    "        # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "        # loss += criterion(decoder_output, current_target)\n",
    "        \n",
    "        # Find out the most probable character (ni) from the softmax distribution produced\n",
    "        ni = F.softmax(decoder_output, dim=1).argmax(1)\n",
    "        #ni = F.softmax(decoder_output, dim=1).multinomial(num_samples = 1)\n",
    "        \n",
    "        if int(ni) == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string += index_to_char[ni.item()]\n",
    "            \n",
    "            # update decoder_input at the next time step to be ni \n",
    "            decoder_input = ni\n",
    "\n",
    "    return gen_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train loss: 1.121 | Val loss: 1.207 | Gen: underay isheway away attay\n",
      "Epoch:   1 | Train loss: 0.567 | Val loss: 0.978 | Gen: unbay-ilway iseway away attyfay\n",
      "Epoch:   2 | Train loss: 0.375 | Val loss: 0.862 | Gen: ubinway isway away atfyway\n",
      "Epoch:   3 | Train loss: 0.278 | Val loss: 0.789 | Gen: unibay isway away atfay\n",
      "Epoch:   4 | Train loss: 0.215 | Val loss: 0.757 | Gen: unsibay isway away attyfay\n",
      "Epoch:   5 | Train loss: 0.174 | Val loss: 0.619 | Gen: uinway-ybay isway away attyfay\n",
      "Epoch:   6 | Train loss: 0.146 | Val loss: 0.680 | Gen: ublingway isway away atfay-ay\n",
      "Epoch:   7 | Train loss: 0.122 | Val loss: 0.625 | Gen: ubidway isway away attfay\n",
      "Epoch:   8 | Train loss: 0.104 | Val loss: 0.573 | Gen: ubingpay isway away attyway\n",
      "Epoch:   9 | Train loss: 0.089 | Val loss: 0.540 | Gen: ubinay-ay isway away attyway\n",
      "Epoch:  10 | Train loss: 0.077 | Val loss: 0.561 | Gen: ubinway isway away attyway\n",
      "Epoch:  11 | Train loss: 0.071 | Val loss: 0.490 | Gen: ubizedway isway away attfyway\n",
      "Epoch:  12 | Train loss: 0.065 | Val loss: 0.457 | Gen: ubivay-aysay isway away attfyway\n",
      "Epoch:  13 | Train loss: 0.054 | Val loss: 0.413 | Gen: ubinay isway away attyfay\n",
      "Epoch:  14 | Train loss: 0.046 | Val loss: 0.505 | Gen: ubinay isway away attyfay\n",
      "Epoch:  15 | Train loss: 0.046 | Val loss: 0.376 | Gen: ubizenay isway away attyway\n",
      "Epoch:  16 | Train loss: 0.039 | Val loss: 0.389 | Gen: unibay isway away attyway\n",
      "Epoch:  17 | Train loss: 0.042 | Val loss: 0.399 | Gen: ubinway isway away attyfay\n",
      "Epoch:  18 | Train loss: 0.036 | Val loss: 0.402 | Gen: ubdingay isway away attyfay\n",
      "Epoch:  19 | Train loss: 0.030 | Val loss: 0.364 | Gen: ubizenay isway away attyway\n",
      "Epoch:  20 | Train loss: 0.027 | Val loss: 0.388 | Gen: uniblay isway away attyfay\n",
      "Epoch:  21 | Train loss: 0.024 | Val loss: 0.359 | Gen: ubizeray isway away attyway\n",
      "Epoch:  22 | Train loss: 0.024 | Val loss: 0.382 | Gen: ubinghay isway away attyway\n",
      "Epoch:  23 | Train loss: 0.026 | Val loss: 0.442 | Gen: ubingway isway away attyfay\n",
      "Epoch:  24 | Train loss: 0.021 | Val loss: 0.376 | Gen: ubingay isway away attyway\n",
      "Epoch:  25 | Train loss: 0.019 | Val loss: 0.366 | Gen: ubingvay isway away attyfay\n",
      "Epoch:  26 | Train loss: 0.024 | Val loss: 0.510 | Gen: ubingway-ay isway-ay away attyfay\n",
      "Epoch:  27 | Train loss: 0.022 | Val loss: 0.440 | Gen: ubingnay isway away attyway\n",
      "Epoch:  28 | Train loss: 0.017 | Val loss: 0.458 | Gen: ubingway isway away attyfay\n",
      "Exiting early from training.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts)\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting early from training.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
