{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "# For interactive debugging\n",
    "#from IPython.core.debugger import set_trace as bp\n",
    "\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "import data_handler\n",
    "from data_handler import *\n",
    "\n",
    "import attn_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters required to train and test the model\n",
    "opts = EasyDict()\n",
    "\n",
    "opts.n_epochs = 100\n",
    "opts.batch_size = 16\n",
    "opts.optimizer = \"Adam\" #\"SGD\"\n",
    "opts.learning_rate = 0.002\n",
    "opts.lr_decay = 0.99\n",
    "opts.hidden_layer_size = 10\n",
    "opts.model_name = \"attention_rnn\"\n",
    "opts.checkpoints_dir = \"./checkpoints/{}_{}_lr_{}_epochs_{}_num_hidden_{}_batchsize_{}\"\\\n",
    "    .format(opts.model_name,opts.optimizer,opts.learning_rate,opts.n_epochs,opts.hidden_layer_size,opts.batch_size)\n",
    "\n",
    "\n",
    "opts.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TEST_SENTENCE = 'i love deep learning'\n",
    "TEST_WORD_ATTENTION = \"attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/attention_rnn_Adam_lr_0.002_epochs_100_num_hidden_10_batchsize_16\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint Directory\n",
    "print(opts.checkpoints_dir)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_dir_if_not_exists(opts.checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pairs, vocab_size, idx_dict = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_to_index\n",
      "{'-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'SOS': 27, 'EOS': 28}\n",
      "index_to_char\n",
      "{0: '-', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'SOS', 28: 'EOS'}\n",
      "start_token\n",
      "27\n",
      "end_token\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for key in (idx_dict.keys()):\n",
    "    print(key) \n",
    "    print(idx_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the line pairs into 8:2, train and val split\n",
    "num_lines = len(line_pairs)\n",
    "num_train = int(0.8 * num_lines)\n",
    "train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = create_dict(train_pairs)\n",
    "val_dict = create_dict(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_dict.keys():\n",
    "#    print(\"Pairs of length {}: {}\".format(key,len(train_dict[key])))\n",
    "    pass\n",
    "#train_dict[(3, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, opts):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm_cell = nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        cell = self.init_hidden(batch_size)\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "        annotations = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
    "            hidden, cell = self.lstm_cell(x, (hidden, cell))\n",
    "            annotations.append(hidden)\n",
    "\n",
    "        annotations = torch.stack(annotations, dim=1)\n",
    "        return annotations, hidden\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return Variable(torch.zeros(bs, self.hidden_size))\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.attention_network = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size,1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, hidden, annotations):\n",
    "        \"\"\"The forward pass of the attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            hidden: The current decoder hidden state. (batch_size x hidden_size)\n",
    "            annotations: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The output must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len, hid_size = annotations.size()\n",
    "        expanded_hidden = hidden.unsqueeze(1).expand_as(annotations)\n",
    "\n",
    "        concat = torch.cat((expanded_hidden, annotations), dim = 2)\n",
    "        reshaped_for_attention_net = concat.reshape(-1, 2*hid_size)\n",
    "        attention_net_output = F.relu(self.attention_network(reshaped_for_attention_net))\n",
    "        unnormalized_attention = self.output_layer(attention_net_output).reshape(batch_size, seq_len, 1)  \n",
    "\n",
    "        return self.softmax(unnormalized_attention)\n",
    "\n",
    "\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
    "        self.attention = Attention(hidden_size=hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev, annotations):\n",
    "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            x: Input token indexes across a batch for a single time step. (batch_size x 1)\n",
    "            h_prev: The hidden states from the previous step, across a batch. (batch_size x hidden_size)\n",
    "            annotations: The encoder hidden states for each step of the input.\n",
    "                         sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch. (batch_size x vocab_size)\n",
    "            h_new: The new hidden states, across a batch. (batch_size x hidden_size)\n",
    "            attention_weights: The weights applied to the encoder annotations, across a batch. (batch_size x encoder_seq_len x 1)\n",
    "        \"\"\"\n",
    "        embed = self.embedding(x)    # batch_size x 1 x hidden_size\n",
    "        embed = embed.squeeze(1)     # batch_size x hidden_size\n",
    "\n",
    "        attention_weights = self.attention.forward(h_prev, annotations).permute(0,2,1)\n",
    "        context = torch.matmul(attention_weights, annotations).squeeze(1)\n",
    "        embed_and_context = torch.cat((context, embed), axis=1)\n",
    "        h_new, c_new = self.lstm_cell(embed_and_context)\n",
    "        output = self.out(h_new)\n",
    "        return output, h_new, c_new, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size, opts = opts)\n",
    "decoder = AttentionDecoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        opts: The input arguments for hyper-parameters and others.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    parameters = list(encoder.parameters())+list(decoder.parameters())\n",
    "    \n",
    "    if opts.optimizer == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(parameters ,lr=opts.learning_rate)\n",
    "    elif opts.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(parameters ,lr=opts.learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(parameters, lr=opts.learning_rate, momentum=0.9)\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoints_dir, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(opts.n_epochs):\n",
    "        \n",
    "        # decay the learning rate of the optimizer\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "\n",
    "        epoch_losses = []\n",
    "\n",
    "        for key in train_dict:\n",
    "\n",
    "            input_strings, target_strings = zip(*train_dict[key])\n",
    "            \n",
    "            input_tensors, output_tensors = [],[]\n",
    "            for s in input_strings:\n",
    "                input_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "            for s in target_strings:\n",
    "                output_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "            \n",
    "            num_tensors = len(input_tensors)\n",
    "            num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "            for i in range(num_batches):\n",
    "\n",
    "                start = i * opts.batch_size\n",
    "                end = start + opts.batch_size\n",
    "\n",
    "                # Inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "                inputs = torch.stack(input_tensors[start:end]).to(opts.device)\n",
    "                targets = torch.stack(output_tensors[start:end]).to(opts.device)\n",
    "               \n",
    "                # The batch size may be different in each epoch\n",
    "                BS = inputs.size(0)\n",
    "\n",
    "                encoder_annotations, encoder_hidden = encoder.forward(inputs)\n",
    "\n",
    "                # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "                decoder_hidden = encoder_hidden.to(opts.device)\n",
    "                decoder_cell = encoder_hidden.to(opts.device)\n",
    "                # First decoder input. This is the essentially be the start_token\n",
    "                decoder_input = start_token * torch.ones(BS,1).long().to(opts.device)\n",
    "\n",
    "                loss = 0.0\n",
    "\n",
    "                seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "                for i in range(seq_len):\n",
    "                    decoder_output, decoder_hidden, decoder_cell, attention_weights = decoder.forward(decoder_input, \\\n",
    "                                                                                        decoder_hidden, \\\n",
    "                                                                                        decoder_cell, \\\n",
    "                                                                                        encoder_annotations)\n",
    "\n",
    "                    current_target = targets[:,i]\n",
    "                    \n",
    "                    # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                    loss += criterion(decoder_output, current_target)\n",
    "\n",
    "                    decoder_input = targets[:,i].unsqueeze(1)\n",
    "\n",
    "                loss /= float(seq_len)\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "                # Compute gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the parameters of the encoder and decoder\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        train_loss = np.mean(epoch_losses)\n",
    "        val_loss = evaluate(val_dict, encoder, decoder, idx_dict, criterion, opts)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            utils.store_checkpoints(encoder, decoder, idx_dict, opts)\n",
    "            \n",
    "        attention_dir = os.path.join(opts.checkpoints_dir,'train_attns')\n",
    "        utils.create_dir_if_not_exists(attention_dir)\n",
    "        \n",
    "        attn_vis.visualize_attention(TEST_WORD_ATTENTION,encoder,decoder,idx_dict,opts,\n",
    "                                      save=attention_dir+\"/attn-epoch-{}.png\".format(epoch))\n",
    "\n",
    "        gen_string = find_pig_latin(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        utils.store_loss_plots(train_losses, val_losses, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_dict, encoder, decoder, idx_dict, criterion, opts):\n",
    "    \"\"\"Evaluates the model on a held-out validation or test set. \n",
    "    This should be pretty straight-forward if you have figured out how to do the training correctly.\n",
    "    From then, it's just copy and paste.\n",
    "\n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for key in data_dict:\n",
    "\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "\n",
    "        input_tensors, output_tensors = [],[]\n",
    "        for s in input_strings:\n",
    "            input_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "        for s in target_strings:\n",
    "            output_tensors.append(torch.LongTensor(string_to_index_list(s, char_to_index, end_token)))\n",
    "\n",
    "        \n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            # Inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "            inputs = torch.stack(input_tensors[start:end]).to(opts.device)\n",
    "            targets = torch.stack(output_tensors[start:end]).to(opts.device)\n",
    "\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_hidden = encoder.forward(inputs)\n",
    "            \n",
    "            decoder_hidden = encoder_hidden.to(opts.device)\n",
    "            decoder_cell = encoder_hidden.to(opts.device)\n",
    "            # First decoder input. This is the essentially be the start_token\n",
    "            decoder_input = start_token * torch.ones(BS,1).long().to(opts.device)\n",
    "            \n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "            for i in range(seq_len):\n",
    "                decoder_output, decoder_hidden, decoder_cell, attention_weights = decoder.forward(decoder_input,\\\n",
    "                                                                                    decoder_hidden,\\\n",
    "                                                                                    decoder_cell, \\\n",
    "                                                                                    encoder_annotations)\n",
    "\n",
    "                current_target = targets[:,i]\n",
    "\n",
    "                # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                loss += criterion(decoder_output, current_target)\n",
    "\n",
    "                # Find out the most probable character (ni) from the softmax distribution produced\n",
    "                ni = F.softmax(decoder_output, dim=1).argmax(1)\n",
    "                \n",
    "                # Update decoder_input at the next time step to be this time-step's target \n",
    "                decoder_input = ni\n",
    "\n",
    "            loss /= float(seq_len)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pig_latin(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    Not much to do here as well. Follows basically the same structure as that of the function evaluate.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    # convert given string to an array of indexes\n",
    "    indexes = torch.LongTensor(string_to_index_list(input_string, char_to_index, end_token)).unsqueeze(0)\n",
    "    indexes = indexes.to(opts.device)\n",
    "\n",
    "    encoder_annotations, encoder_last_hidden = encoder.forward(indexes)\n",
    "\n",
    "    # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "    decoder_hidden = encoder_last_hidden.to(opts.device)\n",
    "    decoder_cell = encoder_last_hidden.to(opts.device)\n",
    "\n",
    "    # Define the first decoder input. This would essentially be the start_token\n",
    "    decoder_input = start_token * torch.ones(1,1).long().to(opts.device)\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "        decoder_output, decoder_hidden, decoder_cell, attention_weights = decoder.forward(decoder_input,\\\n",
    "                                                                            decoder_hidden,\\\n",
    "                                                                            decoder_cell, \\\n",
    "                                                                            encoder_annotations)\n",
    "    \n",
    "        # Find out the most probable character (ni) from the softmax distribution produced\n",
    "        ni = F.softmax(decoder_output, dim=1).argmax(1)\n",
    "        #ni = F.softmax(decoder_output, dim=1).multinomial(num_samples = 1)\n",
    "        #ni = Categorical(F.softmax(decoder_output, dim=1)).sample()\n",
    "\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string += index_to_char[ni.item()]\n",
    "            \n",
    "            # update decoder_input at the next time step to be ni \n",
    "            decoder_input = ni\n",
    "\n",
    "    return gen_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train loss: 2.162 | Val loss: 3.562 | Gen: onay onay ay ay     \n",
      "Epoch:   1 | Train loss: 2.063 | Val loss: 3.503 | Gen: ongingingingingingin ongay intentententententen ay\n",
      "Epoch:   2 | Train loss: 1.978 | Val loss: 3.586 | Gen: ongay ongay eday eday\n",
      "Epoch:   3 | Train loss: 1.904 | Val loss: 3.657 | Gen: ingay ongay eday eday\n",
      "Epoch:   4 | Train loss: 1.835 | Val loss: 3.780 | Gen: ingay ongay eday eday\n",
      "Epoch:   5 | Train loss: 1.767 | Val loss: 3.826 | Gen: ingay oongay eday eday\n",
      "Epoch:   6 | Train loss: 1.710 | Val loss: 3.807 | Gen: ingay ontay eray eday\n",
      "Epoch:   7 | Train loss: 1.661 | Val loss: 3.730 | Gen: ingay ontay erestererererererere ereday\n",
      "Epoch:   8 | Train loss: 1.614 | Val loss: 3.739 | Gen: ingay ontay eesteray eday\n",
      "Epoch:   9 | Train loss: 1.564 | Val loss: 3.675 | Gen: itay ontay eestesay eay\n",
      "Epoch:  10 | Train loss: 1.492 | Val loss: 3.711 | Gen: itay oneday eeseray eay\n",
      "Epoch:  11 | Train loss: 1.433 | Val loss: 3.689 | Gen: itay ouesesay eestay eay\n",
      "Epoch:  12 | Train loss: 1.376 | Val loss: 3.527 | Gen: itay oueeesesay eesteday eatendinay\n",
      "Epoch:  13 | Train loss: 1.321 | Val loss: 3.503 | Gen: itay oueeeeesesay eestay eay\n",
      "Epoch:  14 | Train loss: 1.267 | Val loss: 3.378 | Gen: itay oueeeeeesenay eeshay eay\n",
      "Epoch:  15 | Train loss: 1.213 | Val loss: 3.332 | Gen: itay oueeeeseday eeshay eay\n",
      "Epoch:  16 | Train loss: 1.157 | Val loss: 3.263 | Gen: itay oueeeeesay eeshay eay\n",
      "Epoch:  17 | Train loss: 1.110 | Val loss: 3.260 | Gen: imuay ouseday eeppray earinay\n",
      "Epoch:  18 | Train loss: 1.065 | Val loss: 3.170 | Gen: imay ouseday eeppay earingay\n",
      "Epoch:  19 | Train loss: 1.016 | Val loss: 3.186 | Gen: itay oueeeeray eeppay eaningay\n",
      "Epoch:  20 | Train loss: 0.977 | Val loss: 3.176 | Gen: imay oncay eeppray earningay\n",
      "Epoch:  21 | Train loss: 0.944 | Val loss: 2.904 | Gen: imay ontecay eeppay earningay\n",
      "Epoch:  22 | Train loss: 0.907 | Val loss: 2.964 | Gen: iulay onuecay eeppay earningway\n",
      "Epoch:  23 | Train loss: 0.873 | Val loss: 2.836 | Gen: imay oncay eeppay earningway\n",
      "Epoch:  24 | Train loss: 0.841 | Val loss: 2.791 | Gen: itay oneray eeppay earningway\n",
      "Epoch:  25 | Train loss: 0.822 | Val loss: 2.921 | Gen: iulay onetay eeppray earningway\n",
      "Epoch:  26 | Train loss: 0.794 | Val loss: 2.730 | Gen: iulay ovetay eeppray earningway\n",
      "Epoch:  27 | Train loss: 0.766 | Val loss: 2.916 | Gen: iulay ovelay eeppray earningway\n",
      "Epoch:  28 | Train loss: 0.733 | Val loss: 2.559 | Gen: iulay ovetay eeppay earningway\n",
      "Epoch:  29 | Train loss: 0.721 | Val loss: 2.664 | Gen: iulay ovecay eeppay earningway\n",
      "Epoch:  30 | Train loss: 0.704 | Val loss: 2.646 | Gen: iuy ovetay eeppay earningway\n",
      "Epoch:  31 | Train loss: 0.680 | Val loss: 2.566 | Gen: iuy ovetay eeppay earningway\n",
      "Epoch:  32 | Train loss: 0.666 | Val loss: 2.474 | Gen: iulay oveway eeppay earningway\n",
      "Epoch:  33 | Train loss: 0.653 | Val loss: 2.710 | Gen: iuy ovetay eeppray earningday\n",
      "Epoch:  34 | Train loss: 0.637 | Val loss: 2.462 | Gen: iuy ovecay eeppay earningway\n",
      "Epoch:  35 | Train loss: 0.626 | Val loss: 2.529 | Gen: iulay ovecay eeppay earningway\n",
      "Epoch:  36 | Train loss: 0.604 | Val loss: 2.507 | Gen: iolay oveway eeppay earningway\n",
      "Epoch:  37 | Train loss: 0.609 | Val loss: 2.544 | Gen: iuay oveway eeppay earningway\n",
      "Epoch:  38 | Train loss: 0.581 | Val loss: 2.471 | Gen: itay oveway eeppay earningway\n",
      "Epoch:  39 | Train loss: 0.570 | Val loss: 2.381 | Gen: itay oveway eepday earningway\n",
      "Epoch:  40 | Train loss: 0.558 | Val loss: 2.387 | Gen: iolay oveway eeppay earniningway\n",
      "Epoch:  41 | Train loss: 0.563 | Val loss: 2.312 | Gen: iuay oveway eeppay earningway\n",
      "Epoch:  42 | Train loss: 0.549 | Val loss: 2.328 | Gen: imay oveway eeppay earningway\n",
      "Epoch:  43 | Train loss: 0.539 | Val loss: 2.406 | Gen: iolay oveway eepday earningway\n",
      "Epoch:  44 | Train loss: 0.528 | Val loss: 2.610 | Gen: imay oveway eepday earningway\n",
      "Epoch:  45 | Train loss: 0.522 | Val loss: 2.261 | Gen: imay oveway eepday earningway\n",
      "Epoch:  46 | Train loss: 0.517 | Val loss: 2.335 | Gen: itay ovetay eeppay earningway\n",
      "Epoch:  47 | Train loss: 0.523 | Val loss: 2.256 | Gen: itay oveway eepday earningway\n",
      "Epoch:  48 | Train loss: 0.529 | Val loss: 2.426 | Gen: itay oveway eepday earningway\n",
      "Epoch:  49 | Train loss: 0.498 | Val loss: 2.447 | Gen: iolay ovetay eepday earningay\n",
      "Epoch:  50 | Train loss: 0.481 | Val loss: 2.190 | Gen: iolay ovetay eepday earningway\n",
      "Epoch:  51 | Train loss: 0.474 | Val loss: 2.265 | Gen: itay oveway eepday earningway\n",
      "Epoch:  52 | Train loss: 0.469 | Val loss: 2.309 | Gen: iulay oveway eepday earningay\n",
      "Epoch:  53 | Train loss: 0.467 | Val loss: 2.275 | Gen: itay oveway eepday earningay\n",
      "Epoch:  54 | Train loss: 0.464 | Val loss: 2.027 | Gen: itay oveway eepday earningway\n",
      "Epoch:  55 | Train loss: 0.458 | Val loss: 2.028 | Gen: itay oveway eepday earningway\n",
      "Epoch:  56 | Train loss: 0.489 | Val loss: 2.601 | Gen: iuy ovetay eepway earlingway\n",
      "Epoch:  57 | Train loss: 0.494 | Val loss: 2.278 | Gen: iolay oveway eepday earningay\n",
      "Epoch:  58 | Train loss: 0.460 | Val loss: 2.129 | Gen: iolay ovetay eepday earlingway\n",
      "Epoch:  59 | Train loss: 0.445 | Val loss: 2.166 | Gen: itay ovetay eepday earningway\n",
      "Epoch:  60 | Train loss: 0.442 | Val loss: 1.958 | Gen: itay ovetay eepday earninggay\n",
      "Epoch:  61 | Train loss: 0.439 | Val loss: 2.071 | Gen: iolay oveway eepway earlingway\n",
      "Epoch:  62 | Train loss: 0.445 | Val loss: 2.410 | Gen: iulay ovetay eepday earongway\n",
      "Epoch:  63 | Train loss: 0.436 | Val loss: 1.913 | Gen: iolay ovetay eepday earningway\n",
      "Epoch:  64 | Train loss: 0.428 | Val loss: 2.073 | Gen: itay oveway eepday earningway\n",
      "Epoch:  65 | Train loss: 0.422 | Val loss: 2.179 | Gen: itay oveway eepday earningway\n",
      "Epoch:  66 | Train loss: 0.417 | Val loss: 2.061 | Gen: itay ovetay eepway earningway\n",
      "Epoch:  67 | Train loss: 0.418 | Val loss: 1.958 | Gen: iolay ovetay eepday earlingway\n",
      "Epoch:  68 | Train loss: 0.433 | Val loss: 2.017 | Gen: iolay ovetay eepday earningway\n",
      "Epoch:  69 | Train loss: 0.412 | Val loss: 1.889 | Gen: itay ovetay eepday earningway\n",
      "Epoch:  70 | Train loss: 0.411 | Val loss: 1.993 | Gen: itay ovetay eepday earninggay\n",
      "Epoch:  71 | Train loss: 0.412 | Val loss: 1.886 | Gen: itay oveway eepday earningway\n",
      "Epoch:  72 | Train loss: 0.404 | Val loss: 2.276 | Gen: itay ovetay eepday earningway\n",
      "Epoch:  73 | Train loss: 0.396 | Val loss: 2.034 | Gen: itay ovetay eepday earningway\n",
      "Epoch:  74 | Train loss: 0.399 | Val loss: 1.935 | Gen: itay ovetay eeppay earninggway\n",
      "Epoch:  75 | Train loss: 0.396 | Val loss: 1.857 | Gen: itay ovetay eeppay earningway\n",
      "Epoch:  76 | Train loss: 0.411 | Val loss: 2.366 | Gen: iuy oveway eeppay earninggay\n",
      "Epoch:  77 | Train loss: 0.409 | Val loss: 2.083 | Gen: iolay ovetay eeppay earningway\n",
      "Epoch:  78 | Train loss: 0.397 | Val loss: 1.986 | Gen: itay ovetay eepday earningway\n",
      "Epoch:  79 | Train loss: 0.381 | Val loss: 1.915 | Gen: itay oveway eepday earningway\n",
      "Epoch:  80 | Train loss: 0.377 | Val loss: 1.873 | Gen: itay ovetay eeppay earninggay\n",
      "Epoch:  81 | Train loss: 0.388 | Val loss: 1.840 | Gen: itay oveway eepway earningway\n",
      "Epoch:  82 | Train loss: 0.379 | Val loss: 2.162 | Gen: iolay oveway eeppay earningdpay\n",
      "Epoch:  83 | Train loss: 0.377 | Val loss: 1.878 | Gen: imay oveway eeppay earningway\n",
      "Epoch:  84 | Train loss: 0.367 | Val loss: 1.906 | Gen: itay ovetay eeppay earningway\n",
      "Epoch:  85 | Train loss: 0.361 | Val loss: 1.919 | Gen: itay oveway eeppay earningway\n",
      "Epoch:  86 | Train loss: 0.392 | Val loss: 1.937 | Gen: itay oveway eeppay earningway\n",
      "Epoch:  87 | Train loss: 0.361 | Val loss: 1.774 | Gen: itay ovetay eeppay earninggay\n",
      "Epoch:  88 | Train loss: 0.355 | Val loss: 1.810 | Gen: imay ovetay eeppay earninggay\n",
      "Epoch:  89 | Train loss: 0.359 | Val loss: 1.881 | Gen: iolay oveway eeppay earningway\n",
      "Epoch:  90 | Train loss: 0.365 | Val loss: 1.924 | Gen: itay oveway eeppay earningway\n",
      "Epoch:  91 | Train loss: 0.353 | Val loss: 1.731 | Gen: iotay ovetay eeppay earningway\n",
      "Epoch:  92 | Train loss: 0.341 | Val loss: 1.961 | Gen: itay ovetay eeppay earningway\n",
      "Epoch:  93 | Train loss: 0.340 | Val loss: 1.849 | Gen: itay oveway eeppay earningway\n",
      "Epoch:  94 | Train loss: 0.339 | Val loss: 1.661 | Gen: itay ovetay eeppay earningway\n",
      "Epoch:  95 | Train loss: 0.336 | Val loss: 1.661 | Gen: itay oveway eeppay earningway\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  96 | Train loss: 0.335 | Val loss: 1.902 | Gen: itay oveway eepday earningway\n",
      "Epoch:  97 | Train loss: 0.334 | Val loss: 1.634 | Gen: itay ovetay eeppay earninggay\n",
      "Epoch:  98 | Train loss: 0.340 | Val loss: 1.770 | Gen: imay oveway eepway earningway\n",
      "Epoch:  99 | Train loss: 0.336 | Val loss: 1.832 | Gen: itay oveway eepway earninggay\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts)\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting early from training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itay amay appy\n",
      "istay isray otnay iggay atinlay\n",
      "istay odelmay isray orkingway\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"i am happy\",\"this is not pig latin\",\"this model is working\"]\n",
    "\n",
    "for test in test_sentences:\n",
    "    print(find_pig_latin(test, encoder, decoder, idx_dict, opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37089201877934275, 0.8539570757880617)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy(data_dict, encoder, decoder, opts, idx_dict):\n",
    "    word_accuracy, letter_accuracy, total_words, total_letters = 0,0,0,0\n",
    "    for key in data_dict:\n",
    "        for k,v in data_dict[key]:\n",
    "            v_ = translate(k, encoder, decoder, idx_dict, opts)\n",
    "            total_words += 1\n",
    "            total_letters += len(v_)\n",
    "            if v_==v:\n",
    "                word_accuracy += 1\n",
    "                letter_accuracy += len(v)\n",
    "            else:\n",
    "                if len(v_)<len(v):\n",
    "                    v_ += (len(v)-len(v_)) * '0'\n",
    "                elif len(v_)>len(v):\n",
    "                    v += (len(v_)-len(v)) * '0'\n",
    "                \n",
    "                for i in range(len(v)):\n",
    "                    if v[i]==v_[i]:\n",
    "                        letter_accuracy += 1\n",
    "        \n",
    "    return word_accuracy/total_words, letter_accuracy/total_letters\n",
    "\n",
    "\n",
    "get_accuracy(val_dict, encoder, decoder, opts, idx_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
