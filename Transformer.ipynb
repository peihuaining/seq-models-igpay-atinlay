{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_handler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates source and target tensors for the pairs: \n",
    "# Shape of source (NumExamples, MaxSentLength), Shape of target (NumExamples, MaxSentLength). \n",
    "\n",
    "# Ensures source and targets have the same shape by padding them to the same length with end tokens. \n",
    "# Transformer implementation predicts one token for each input token\n",
    "# During inference sufficiently pad the input with end tokens.\n",
    "\n",
    "def convert_dataset_to_tensor(data_pairs, max_len):\n",
    "    source_rows = []\n",
    "    target_rows = []\n",
    "    for pair in data_pairs:\n",
    "        source, target = pair\n",
    "        \n",
    "        source_index_list = string_to_index_list(source, char_to_index, end_token)\n",
    "        source_index_list = source_index_list + [end_token for et in range(max_len - (len(source_index_list)))]\n",
    "        \n",
    "        target_index_list = [start_token] + string_to_index_list(target, char_to_index, end_token)\n",
    "        target_index_list = target_index_list + [end_token for et in range(max_len - (len(target_index_list)))]\n",
    "        \n",
    "        source_rows.append( torch.LongTensor(source_index_list) )\n",
    "        target_rows.append( torch.LongTensor(target_index_list) )\n",
    "        \n",
    "    source_tensors = torch.stack(source_rows)\n",
    "    target_tensors = torch.stack(target_rows)\n",
    "\n",
    "    return source_tensors, target_tensors\n",
    "\n",
    "line_pairs, vocab_size, idx_dict = load_data()\n",
    "\n",
    "char_to_index = idx_dict['char_to_index']\n",
    "start_token = idx_dict['start_token']\n",
    "end_token = idx_dict['end_token']\n",
    "\n",
    "num_lines = len(line_pairs)\n",
    "num_train = int(0.8 * num_lines)\n",
    "train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
    "\n",
    "source_strings = [pair[0] for pair in line_pairs]\n",
    "target_strings = [pair[1] for pair in line_pairs]\n",
    "\n",
    "max_input_len = max([ len(source_string)+1 for source_string in source_strings])\n",
    "max_target_len = max([ len(target_string)+2 for target_string in target_strings])\n",
    "max_len = max(max_input_len, max_target_len)\n",
    "\n",
    "train_inputs, train_targets = convert_dataset_to_tensor(train_pairs, max_len)\n",
    "val_inputs, val_targets = convert_dataset_to_tensor(val_pairs, max_len)\n",
    "\n",
    "print (\"Train Sequences\", train_inputs.size(), train_targets.size())\n",
    "print (\"Val Sequences\", val_inputs.size(), val_targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, emb_size, nhead, nhid, nlayers):\n",
    "        \"\"\"\n",
    "        emb_size: Embedding Size for the input\n",
    "        ntoken: Number of tokens Vocab Size\n",
    "        nhead: Number of transformer heads in the encoder\n",
    "        nhid: Number of hidden units in transformer encoder layer\n",
    "        nlayer: Number of layers in transformer encoder\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        \n",
    "        # Initialized position input embedding, position encoding layers\n",
    "        self.input_embedding = nn.Embedding(ntoken, emb_size)\n",
    "        self.pos_encoding = PositionalEncoding(emb_size)\n",
    "        \n",
    "        # Initialized transformer encoder with nlayers and each layer having nhead heads and nhid hidden units.\n",
    "        self.encoder_layers = TransformerEncoderLayer(emb_size, nhead, nhid)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layers, nlayers)\n",
    "        \n",
    "        # Decoder implemented as a linear layer on top of encoding layer\n",
    "        self.decoder = nn.Linear(emb_size, ntoken)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        src: tensor of shape (seq_len, batch_size)\n",
    "        \n",
    "        Returns:\n",
    "            output: tensor of shape (seq_len, batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        # Embed the source sequences and add the positional encoding.\n",
    "        src = self.input_embedding(src)\n",
    "        src = self.pos_encoding(src)\n",
    "        # Pass the sequence to the transformer encoder\n",
    "        output = self.transformer_encoder(src)\n",
    "        # Generate and return scores using decoder linear layer\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds positional embedding to the input for conditioning on time. \n",
    "    From the paper \"Attention is all you need\"\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: tensor of shape (seq_len, batch_size, embedding_size)\n",
    "        Returns:\n",
    "            x: tensor of shape (seq_len, batch_size, embedding_size)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ntokens = vocab_size # the size of vocabulary\n",
    "batch_size = 16\n",
    "emsize = 50 # embedding dimension\n",
    "nhid = 50 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "lr = 0.002 # learning rate\n",
    "epochs = 50 # The number of epochs\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(inputs, targets, batch_no, batch_size, max_num):\n",
    "    start = batch_no * batch_size\n",
    "    end = min(start + batch_size, max_num)\n",
    "    \n",
    "    return inputs[start:end].t(),targets[start:end].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        num_batches = int(np.ceil(train_inputs.size()[0] / float(batch_size)))\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_no in range(num_batches):\n",
    "            # Read input for a batch\n",
    "            inputs, target = get_batch(train_inputs, train_targets, batch_no, batch_size, train_inputs.size()[0])\n",
    "\n",
    "            # Process input to the model, get the ouput, compute loss\n",
    "            optimizer.zero_grad()\n",
    "            output = net(inputs)\n",
    "            output_flatten = output.view(-1,ntokens)\n",
    "            \n",
    "            # CELoss - Output is (N,C) and Target is (N)\n",
    "            loss = criterion(output_flatten, target.reshape(-1))\n",
    "            \n",
    "            # Backpropagate loss\n",
    "            loss.backward()\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum of training loss over the batches\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Average training loss over the batches\n",
    "        train_loss /= num_batches\n",
    "\n",
    "        val_loss, val_acc = evaluate(net, val_inputs, val_targets)\n",
    "        sample_translation = translate(net, \"testsequence\", idx_dict, max_len)\n",
    "        \n",
    "        # Check progress of training\n",
    "        #print (\"Epoch:{:3d} | Train Loss:{:.5f} \".format(epoch, train_loss))\n",
    "        print (\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Val Acc:{} \".format(epoch, train_loss, val_loss, val_acc))\n",
    "        print (sample_translation)\n",
    "\n",
    "        # Move to training mode for the next batch\n",
    "        net.train() \n",
    "\n",
    "        # LR schedular after each epoch\n",
    "        scheduler.step()\n",
    "\n",
    "def evaluate(net, val_inputs, val_targets):\n",
    "    \"\"\"\n",
    "    # Return validation loss and\n",
    "    # Accuracy -> percentage of validation sequences that were translated correctly.\n",
    "    \"\"\"\n",
    "    # Turn on the evaluation mode\n",
    "    net.eval() \n",
    "    val_loss = 0.0\n",
    "\n",
    "    num_batches = int(np.ceil(val_inputs.size()[0] / float(batch_size)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_no in range(num_batches):\n",
    "            # Read input for a batch\n",
    "            inputs, target = get_batch(val_inputs, val_targets, batch_no, batch_size, val_inputs.size()[0])\n",
    "            output = net(inputs)\n",
    "            output_flatten = output.view(-1,ntokens)\n",
    "            loss = criterion(output_flatten, target.reshape(-1))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "        # Average training loss over the batches\n",
    "        val_loss /= num_batches\n",
    "\n",
    "    #TODO: val_accuracy\n",
    "    val_accuracy = None\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def translate(net, input_sequence, idx_dict, max_len):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    \"\"\"\n",
    "    # Translates the input sequence to piglatin using the trained model\n",
    "    net.eval()\n",
    "    \n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    \n",
    "    gen_string = ''\n",
    "    \n",
    "    # Convert input_sequence to a tensor of appropriate shape of (1,max_len)\n",
    "    index_list = string_to_index_list(input_sequence, char_to_index, end_token)\n",
    "    index_list = index_list + [end_token for et in range(max_len - (len(index_list)))]\n",
    "    indexes = torch.LongTensor(index_list).reshape(1,-1)\n",
    "    \n",
    "    # Process it through the model\n",
    "    output = net(indexes).squeeze(0)\n",
    "    n = F.softmax(output,dim = 1).argmax(dim = 1)\n",
    "\n",
    "    # Predict translation\n",
    "    for i in range(max_len):\n",
    "        if int(n[i]) == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string += index_to_char[n[i].item()]\n",
    "\n",
    "    return gen_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
